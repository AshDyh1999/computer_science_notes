## 0. 语法
1. `:`表示层级关系
2. `- `:表示列表项
3. `  `:两个空格表示层级关系
4. 检查命令
    1. onlyif 检查的命令,仅当onlyif选项指向的命令返回true时才执行name定义的命令
    2. unless 检查的命令,仅当unless选项指向的命令返回false时才执行name定义的命令
        +unless 和 name同级
5. 检查状态(requisites)
    1. require: 我依赖某个状态,里面的状态执行成功后才能执行cmd.run.是`cmd.run的子集`
        + 放在某个模块下后,只有require里面的结果成立了,才会执行该模块
    2. watch: 我关注某个状态












----------------------------------------------------------------





## 1. SaltStack状态文件

### 1-1. jinja
同样是`sls`后缀的文件,可能是普通文件,也可能是模板文件
+ 定义一个模板文件,这样其他文件可以从这个模板文件里导出变量
#### 1-1-1. 区分jinja2文件和普通文件
+ 如果有`- template: jinja`,就是模板
#### 1-1-2. 使用
1. 将文件管理的文件写成模板文件,定义变量
+ 变量列表 `- defaults:`,其下一级为列表项,格式为`key: value`
+ `- defaults:`写在和source同级的位置
2. 在文件管理的文件里指明的source文件里使用变量
##### 1-1-2-1. 定义happy变量名
1. 将文件管理的文件写成模板文件,定义变量
```
cd /srv/salt/base/
sudo vim dns.sls
###############
/etc/resolv.conf:
  file.managed:
    - source: salt://files/resolv.conf
    - user: root
    - group: root
    - mode: 644
    - template: jinja
    - defaults:
      DNS_SERVER: happy
###############
```
2. 在文件管理的文件里指明的source文件里使用变量
```
cd /srv/salt/base
sudo vim files/resolv.conf
################
options timeout:2 attempts:3 rotate single-request-reopen
; generated by /usr/sbin/dhclient-script
; {{ DNS_SERVER }}
nameserver 100.100.2.136
nameserver 100.100.2.138
################
```
3. 执行配置管理
```
sudo salt '*' state.highstate
```
#### 1-1-3. 提取grains的值
模板文件下的实体文件可以使用grains里面的值
+ 格式`grains['key']`
1. 在实体文件中使用grains提取出ip地址
```
cd /srv/salt/base
sudo vim files/resolv.conf
################
options timeout:2 attempts:3 rotate single-request-reopen
; generated by /usr/sbin/dhclient-script
; {{ grains['fqdn_ip4'] }}
nameserver 100.100.2.136
nameserver 100.100.2.138
################
```
2. 测试
```
sudo salt '*' state.highstate 
```








### 1-2. top.sls
+ 一定放在base环境下
+ `top.sls`是top file,因为master配置文件里写着`state_top: top.sls`
```
环境:
  匹配minion:
    - 加载什么模块
```
#### 1-2-1. 规则
1. 匹配minion
+ 全名/通配符等
+ grain/pillar(需要在其下的列表项中指出是哪个)
2. 加载什么模块
+ 我们在环境对应目录下写的sls文件的文件名(去掉`.sls`后缀)
###### 1-2-1. top.sls的例子
```
base:
  'web:hello':
    - match: grain
    - apachezabbix-agent-install:
  pkg.installed
    - name: zabbix-agent

  file.managed:
    - name: /etc/zabbix_agentd.conf
    - source: salt://init/files/zabbix_agentd.
conf
    - template: jinja
    - defaults:
      Server: {{ pillar['zabbix_agent']['Zabbi
x_Server'] }}
    - require:
      - pkg: zabbix-agent-install:
 
  service.running:
    - enable: True
    - watch:

```



















----------------------------------------------------------------



## 2. 普通状态
### 2-1. 文件管理
> https://docs.saltstack.com/en/latest/ref/states/all/salt.states.file.html#module-salt.states.file
#### 2-1-1. 文件管理
文件管理有多种写法.第一级不是id就是name声明
    1. 取id
        + 必须在`file.managed`子集中定义文件在minion端的具体位置
        + 例子在安装haproxy时的压缩包处理
    ```
    id名:
      file.managed:
        - name: minion端的文件名
        - source: 相对于在哪个环境,就在哪个环境里找,具体的文件名
        - 用户
        - 组
        - 权限
    ```
    2. 不取id
    ```
    minion端的文件名:
      file.managed:
        - source: 相对于在哪个环境,就在哪个环境里找,具体的文件名
        - 用户
        - 组
        - 权限
    ```
#### 2-1-2. 文件追加
内容不用加双引号
```
minion端的文件名:
  file.append:
    - text:
      - 内容
```
#### 2-1-3. 修改内核参数
```
net.ipv4.ip_local_port_range:
  sysctl.present:
    - value: 10000 65000
fs.file-max:
  sysctl.present:
    - value: 100000
```
#### 2-1-4. 包含其他sls文件
当执行包含其他sls文件的sls文件时,会依次执行里面的sls文件
+ top file只需要使用这个sls文件,就可以执行里面的所有文件
+ 该文件命名随意
+ 如果该文件在base环境下的init目录下,和`dns.sls`等同级,但include这些同级文件时,仍然要从base环境本身目录找起
```
include:
  - init.dns
  - init.history
  - init.audit
  - init.sysctl
```

### 2-2. 配置
#### 2-2-1. 在master配置文件里设置top file的目录
```
sudo vim /etc/salt/master
##############
file_roots:
  base:
    - /srv/salt/base
  test:
    - /srv/salt/test
  prod:
    - /srv/salt/prod
##############
sudo systemctl restart salt-master
sudo mkdir /srv/salt/{base,test,prod}
```
#### 2-2-2. 写基本的文件管理
```
sudo mkdir /srv/salt/base/files
cd /srv/salt/base/
sudo vim dns.sls
############### 不取id
/etc/resolv.conf:
  file.managed:
    - source: salt://files/resolv.conf
    - user: root
    - group: root
    - mode: 644
###############
sudo mv /etc/resolv.conf /srv/salt/base/files/
```
#### 2-2-3. 执行文件状态
##### 2-2-3-1. 直接执行
```
sudo salt '*' state.sls dns
```

##### 2-2-3-2. 高级状态,每次执行状态都会执行
从top file开始读,top file怎么指定状态就执行
1. 修改base环境下的`top.sls`文件
```
base:
  '*':
    - dns
```
2. 执行高级状态
```
sudo salt '*' state.highstate
```
---------------------------

## 3. 应用
### 3-1. 系统初始化
#### 3-1-1. base环境设置为`/srv/salt/base`目录
#### 3-1-2. 在base环境下创建1个init文件夹,专门放系统初始化的文件
结构为
```
.
|-- init
|   |-- audit.sls
|   |-- dns.sls
|   |-- files
|   |   `-- resolv.conf
|   |-- history.sls
|   `-- sysctl.sls
`-- top.sls
```
#### 3-1-3. 放置系统初始化文件
> https://github.com/orris27/orris/tree/master/linux/saltstack/example/init_example

#### 3-1-0. 问题
##### 3-1-0-1. 出现冲突的id
```
    Data failed to compile:
----------
    Detected conflicting IDs, SLS IDs need to be globally unique.
    The conflicting ID is '/etc/profile' and is found in SLS 'base:init.history' and SLS 'base:init.audit'
```
###### 3-1-0-1-1. 解决
`init/history.sls`和`init/audit.sls`都对同一个文件进行追加操作,比如说第一行都是`/etc/profile:`
+ 合并
+ 其中一个妥协
  - `init/audit.sls`换成`/etc/bashrc:`


### 3-2. 功能模块
1. 功能模块统一放在生产环境下,因为不是所有服务器都要安装这些功能
2. 不同sls文件对应不同功能
3. 功能可能需要依赖包,我们单独创建1个pkg目录存放
#### 3-2-1. 安装haproxy和keepalived
1. 环境搭建
    1. 指定(假设)`/srv/salt/prod`是SaltStack-master的生产环境
    2. 在生产环境下创建依赖包和功能目录
        + 1个功能<=>1个目录
        + pkg是所有功能的依赖包的目录,那么是不是通过不同的sls文件来进一步区分这个依赖包是属于哪个功能的?
        + 配置文件的修改单独放到另一个地方,因为配置文件的修改如果放到安装里面,复用性就会下降
    ```
    sudo mkdir /srv/salt/prod/{pkg,haproxy}
    sudo mkdir /srv/salt/prod/haproxy/files
    cd /srv/salt/prod/pkg/
    ``` 
2. 编辑依赖包安装
    + `pkg-init`是id
    + `pkg.installed`为模块下的一个方法
```
sudo vim /srv/salt/prod/pkg/pkg-init.sls
###############
pkg-init:
  pkg.installed:
    - names:
      - gcc
      - gcc-c++
      - glibc
      - make
      - autoconf
      - openssl
      - openssl-devel
###############
```
3. 源码安装haproxy
    1. 下载源码
    2. 解压并进入目录
    3. 设置编译参数
        + haproxy的linux内核参数通过`less README`可以查看到
    4. 编译并安装
    5. 设置软连接
```
wget http://www.haproxy.org/download/1.8/src/haproxy-1.8.12.tar.gz
tar -zxf haproxy-1.8.12.tar.gz
cd haproxy-1.8.12
sudo make TARGET=linux2628 PREFIX=/usr/local/haproxy-1.8.12 && \
sudo make install PREFIX=/usr/local/haproxy-1.8.12
sudo ln -s /usr/local/haproxy-1.8.12/ /usr/local/haproxy
```
4. 编写salt版本的haproxy
    1. 修改并拷贝实体文件到salt-master指定环境下
        1. 拷贝hapoxy的源码压缩包到salt生产环境下的功能目录下的files中
        2. 修改`examples/haproxy.init`文件,将`BIN=/usr/sbin/$BASENAME`修改成`BIN=/usr/local/haproxy/sbin/$BASENAME`
            + `/usr/local/haproxy`是我们安装haproxy的目录,因此要在这个目录下的`sbin`中去找`$BASENAME`("hapoxy.init")
        3. 拷贝`examples/haproxy.init`到salt生产环境下的功能目录下的files中
            + `haproxy.init`是实在的文件,所以放入files目录中
    2. 编写安装haproxy的sls文件
        1. 安装依赖包
        2. 将master端的源码压缩包发送到minion端
            + `haproxy-install:`是自定义的id,在里面写了个文件管理
        3. 远程编译安装
            + 在sls(salt state)文件中,用`&&`连接所有命令
            + 如果实现已经安装了haproxy,就不用执行这里的安装
                - 检查`/usr/local/haproxy`是否存在
            + 如果依赖包安装成功并且压缩包确定送达,才能执行
            + require依赖时指明模块和id.格式为`模块: id名`=>这个id下面有xx模块,我们依赖这个模块
                - `pkg: pkg-init`是在`pkg-init.sls`文件里定义的id(`pkg-init`)和这个id下使用的pkg模块
        4. 推送其他相关实体文件
            1. 将解压后的`examples/haproxy.init`推送的minion的`/etc/init.d`下
                + 普通文件f1移动到目录d下,则`name`应该写`d/f2`的形式,这样f1重命名成f2,并放在d目录下
        5. (部分服务可选)修改minion端相关内核参数等
            1. 允许备机监听其他服务器的ip和端口
                + 改变内核参数中的ip_nonlocal_bind为1,即允许
        6. 创建配置文件的目录
            + 利用file.directory方法来创建`/etc/haproxy`
    3. 在master端执行状态
        + 使用env指定prod
```
sudo vim ~/tools/haproxy-1.8.12/examples/haproxy.init
##############
# BIN=/usr/sbin/$BASENAME
BIN=/usr/local/haproxy/sbin/$BASENAME
##############

sudo cp ~/tools/haproxy-1.8.12.tar.gz /srv/salt/prod/haproxy/files/
sudo cp ~/tools/haproxy-1.8.12/examples/haproxy.init /srv/salt/prod/haproxy/files/
cd /srv/salt/prod/haproxy
sudo vim install.sls
##############
include:
  - pkg.pkg-init

haproxy-install:
  file.managed:
    - name: /home/orris/tools/haproxy-1.8.12.tar.gz
    - source: salt://haproxy/files/haproxy-1.8.12.tar.gz
    - user: root
    - group: root
    - mode: 755
  cmd.run:
    - name: cd /home/orris/tools && tar -zxf haproxy-1.8.12.tar.gz && cd haproxy-1.8.12 && sudo make TARGET=linux2628 PREFIX=/usr/local/haproxy-1.8.12 && sudo make install PREFIX=/usr/local/haproxy-1.8.12 && sudo ln -s /usr/local/haproxy-1.8.12/ /usr/local/haproxy
    - unless: test -d /usr/local/haproxy
    - require:
      - pkg: pkg-init
      - file: haproxy-install

haproxy-init:
  file.managed:
    - name: /etc/init.d/haproxy
    - source: salt://haproxy/files/haproxy.init
    - user: root
    - group: root
    - mode: 755
    - require:
      - cmd: haproxy-install
  cmd.run:
    - name: chkconfig --add haproxy
    - unless: chkconfig --list | grep haproxy
    - require:
      - file: haproxy-init


net.ipv4.ip_nonlocal_bind:
  sysctl.present:
    - value: 1

haproxy-config-dir:
  file.directory:
    - name: /etc/haproxy
    - user: root
    - group: root
    - mode: 755
##############

salt 'linux-node3.*' state.sls haproxy.install env=prod
```

#### 3-2-0. 问题
1. ` The function "state.highstate" is running as PID 6570 and was started at 2018, Jul 29 13:32:06.608152 with jid 20180729133206608152`
    1. 产生原因
    + 执行了`state.highstate`+`Ctrl+C`,导致minion端上有1个job还在执行
    2. 解决
    + 可以直接执行`salt '*' saltutil.signal_job $(salt-run jobs.active | head -n1 | cut -c 1-20) 15`
        1. 查看现在运行中的job
        ```
        salt-run jobs.active
        ```
        2. 温柔kill这个jobdeng
        + `15`是singal_job指定的信号,不能改变
        + `20180730215933414927`是job id
        ```
        salt '*' saltutil.signal_job 20180730215933414927 15
        ```
        

### 3-3. 业务模块
配置文件放在业务模块
1. 创建集群用的配置文件的salt目录
```
mkdir /srv/salt/prod/cluster
mkdir /srv/salt/prod/cluster/files
```
2. 配置haproxy
    + 在cluster的files里存放haproxy的实际配置文件
    + 实际的配置文件对应不同的状态文件
    + 不同的配置方式在master端采用不同的名字(cfg文件/sls文件)命名.但是状态文件在传输配置文件时,都会统一变成对应配置文件
        - haproxy-outside.cfg & haproxy-outside.sls (master) => haproxy.cfg (minion)
    + enable表示允许开机自启动
    + `reload`是根据`watch`来决定的,即如果watch的对象(这里是haproxy的配置文件)如果发生变化的话,就reload
    + `reload`如果不写就是restart,具体怎么reloa因情况而异
> https://github.com/orris27/orris/blob/master/linux/haproxy/installation.md
```
cd /srv/salt/prod/cluster/files
创建外网的负载均衡
vim haproxy-outside.cfg
###########################
# 使用第一个配置文件,即含有keepalived的配置文件
###########################
```
3. 设置状态文件
    1. 设置haproxy的状态文件
        1. 设置将haproxy中的配置文件推送到minion端
        2. 设置开机自启动
    2. 设置top file
    + top file中使用prod环境
```
cd /srv/salt/prod/cluster
cat > haproxy-outside.sls <<EOF
include:
  - haproxy.install

haproxy-service:
  file.managed:
    - name: /etc/haproxy/haproxy.cfg
    - source: salt://cluster/files/haproxy-outside.cfg
    - user: root
    - group: root
    - mode: 644
  service.running:.
    - name: haproxy
    - enable: True
    - reload: True
    - require:
      - cmd: haproxy-init
    - watch:
      - file: haproxy-service
EOF

cd /srv/salt/base
cat >> top.sls <<EOF

prod:
  'linux-node1.example.com':
    - cluster.haproxy-outside
  'linux-node3.example.com':zabbix-agent-install:
  pkg.installed
    - name: zabbix-agent

  file.managed:
    - name: /etc/zabbix_agentd.conf
    - source: salt://init/files/zabbix_agentd.
conf
    - template: jinja
    - defaults:
      Server: {{ pillar['zabbix_agent']['Zabbi
x_Server'] }}
    - require:
      - pkg: zabbix-agent-install:
 
  service.running:
    - enable: True
    - watch:

    - cluster.haproxy-outside
EOF
```
4. minion端开放相关端口
    1. 关闭minion端的80端口服务
    2. 所有的minion端修改原来Web服务的监听端口为8080,并启动
    + 比如说`linux-node1`(既是master也是minion的服务器)上修改httpd配置文件,使监听8080,并启动
    ```
    vim /etc/httpd/conf/httpd.conf
    ##################
    # Listen 80
    Listen 8080
    ##################
    apachectl
    ```
    
5. 执行salt命令
```
salt '*' state.highstate test=True
salt '*' state.highstate
```

6. 访问haproxy的网站
    1. 在浏览器里输入`http://47.100.185.187:8888/haproxy-status`
    2. 用户名和密码为`haproxy`和`saltstack`(均在haproxy的配置文件里写着)

7. 发现proxy的网站中两个节点都没有工作
+ 通过看backend下面的第一列,如这里的web-node1和web-node2,如果是红色的,就说明没有工作;如果是绿色的就是工作状态
    1. 查看错误信息,使用`curl -I http://172.19.28.82:8080`,发现是403错误
    + 注意是查看8080端口,因为我们的Web服务器就是启动在8080端口
    2. 检查对应minion端的Web服务是否在8080端口开启
    3. 检查Web服务器的物理目录`/var/www/html`处是否有index文件,如果没有index文件,就创建一个
    ```
    cat > /var/www/html/index.html<<EOF
    linux-node1
    EOF
    ```
    4. 刷新proxy网页,即`http://47.100.185.187:8888/haproxy-status`,发现两个节点都变绿色了,说明正常工作了
    
    
#### 3-3-0. 问题
1. `Too many functions declared in state 'file' in SLS 'cluster.haproxy-outside'`
+ 我的`haproxy-outside.sls`文件中的`mode:644`的冒号后面没有空格.加了空格后就好了
2. 每次执行`salt.highstate`的时候,同时为master和minion的服务器总是没有响应
    1. 原因
    + 在salt执行的命令中有修改内核参数的命令,如初始化系统时修改ip_local_port_range和文件描述符,以及安装haproxy的时候修改是否能监听非本机ip/port
    2. 解决
    + 要么区分这个服务器和纯minion服务器,要么直接都不修改内核参数



--------------------------------------
## 4. Zabbix
1. 创建zabbix所需目录环境
+ 使用base环境下的init目录就好了
```
cd /srv/salt/base/init/
```
2. 写zabbix状态文件
```
cat > zabbix-agent.sls<<EOF
zabbix-agent-install:
  pkg.installed
    - name: zabbix-agent

  file.managed:
    - name: /etc/zabbix_agentd.conf
    - source: salt://init/files/zabbix_agentd.
conf
    - template: jinja
    - defaults:
      Server: {{ pillar['zabbix_agent']['Zabbi
x_Server'] }}
    - require:
      - pkg: zabbix-agent-install:
 
  service.running:
    - enable: True
    - watch:
      - pkg: zabbix-agent-install
      - file: zabbix-agent-install
EOF
```
3. 写pillar
+ > https://github.com/orris27/orris/blob/master/linux/saltstack/pillar.md
    1. 在master配置文件添加pillar目录及环境,并重启
    ```
    sudo vim /etc/salt/master
    ############################
    pillar_roots:
      base:
        - /srv/pillar/base
    ############################
    sudo systemctl restart salt-master
    ```
    2. 创建/srv/pillar/base目录
    ```
    sudo mkdir /srv/pillar/base
    ```
    3. 在pillar的base环境下随便编写1个apahce.sls
    ```
    cd /srv/pillar/base
    cat >zabbix.agent
    ```
    4. 写状态文件(top.sls)
    ```
    cd /srv/pillar/base
    cat > top.sls <<EOF
    base:
      '*':
        - zabbix
    EOF
    ```
    5. 检测master端是否能获得minion的pillar数据
    6. 通知minion我们已经设置了pillar
    7. 检测


